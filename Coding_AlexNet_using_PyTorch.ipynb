{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO65ZX8xc9OAOmTBQnIbSjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashsTiwari/ML_DL_revision/blob/main/Coding_AlexNet_using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Byf0zZORZ4Yw"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ifigotin/imagenetmini-1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV64lzJiZ_hM",
        "outputId": "2b39558b-051a-4196-bea3-41972839fc93"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ifigotin/imagenetmini-1000\n",
            "License(s): unknown\n",
            "Downloading imagenetmini-1000.zip to /content\n",
            "100% 3.91G/3.92G [01:02<00:00, 60.5MB/s]\n",
            "100% 3.92G/3.92G [01:02<00:00, 66.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref=zipfile.ZipFile('/content/imagenetmini-1000.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "6jBhXxBSaAwc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "htpWU1G6aCFL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "2u2hyqfTaDTA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=datasets.ImageFolder(root='/content/imagenet-mini/train',transform=transform)\n",
        "val_dataset=datasets.ImageFolder(root='/content/imagenet-mini/val',transform=transform)"
      ],
      "metadata": {
        "id": "Is091bpfaLA0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "V9aEYyYEbf72"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self,input_features):\n",
        "    super().__init__()\n",
        "    self.features=nn.Sequential(\n",
        "       nn.Conv2d(input_features, 96, kernel_size=11, stride=4, padding=0),\n",
        "       nn.ReLU(),\n",
        "       nn.MaxPool2d(kernel_size=3,stride=2),\n",
        "       nn.Conv2d(96, 256, kernel_size=5, padding=0),\n",
        "       nn.ReLU(),\n",
        "       nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
        "       nn.Conv2d(256, 384, kernel_size=3, padding=0),\n",
        "       nn.ReLU(),\n",
        "       nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "       nn.ReLU(),\n",
        "       nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "       nn.ReLU(),\n",
        "       nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "    )\n",
        "    self.classifier=nn.Sequential(\n",
        "       nn.Flatten(),\n",
        "       nn.Linear(4*4*256, 4096),\n",
        "       nn.ReLU(),\n",
        "       nn.Dropout(0.5),\n",
        "       nn.Linear(4096, 4096),\n",
        "       nn.ReLU(),\n",
        "       nn.Dropout(0.5),\n",
        "       nn.Linear(4096, 1000)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "     x=self.features(x)\n",
        "     x=self.classifier(x)\n",
        "     return x"
      ],
      "metadata": {
        "id": "px8OthIXbpec"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "model=AlexNet(3)\n",
        "lr = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "EtvBiZbvi-hU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "w1E-o48DjK-8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = torch.randn(1, 3, 227, 227).to(device)\n",
        "print(model.features(dummy).shape)"
      ],
      "metadata": {
        "id": "9-oNKgffj7dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b8bc1d-37b9-4da6-e2ae-8fac42d52ed1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = outputs.max(1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "q_Q0h6BJeE5P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader, val_loader, optimizer, criterion, device, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsoG-UAJedPm",
        "outputId": "3b787f13-0665-4413-ecb0-c0b59bb761eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] | Train Loss: 6.8111 | Val Loss: 6.8421 | Val Acc: 0.08%\n",
            "Epoch [2/10] | Train Loss: 6.7959 | Val Loss: 6.8371 | Val Acc: 0.10%\n",
            "Epoch [3/10] | Train Loss: 6.7819 | Val Loss: 6.8322 | Val Acc: 0.10%\n",
            "Epoch [4/10] | Train Loss: 6.7716 | Val Loss: 6.8152 | Val Acc: 0.20%\n",
            "Epoch [5/10] | Train Loss: 6.7556 | Val Loss: 6.8071 | Val Acc: 0.25%\n",
            "Epoch [6/10] | Train Loss: 6.7351 | Val Loss: 6.7855 | Val Acc: 0.31%\n",
            "Epoch [7/10] | Train Loss: 6.7002 | Val Loss: 6.7528 | Val Acc: 0.25%\n",
            "Epoch [8/10] | Train Loss: 6.6422 | Val Loss: 6.6814 | Val Acc: 0.43%\n",
            "Epoch [9/10] | Train Loss: 6.5808 | Val Loss: 6.6562 | Val Acc: 0.66%\n",
            "Epoch [10/10] | Train Loss: 6.5296 | Val Loss: 6.5963 | Val Acc: 0.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is just a basic version, more optimisations can be done"
      ],
      "metadata": {
        "id": "B4qucmNsvM8e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "48tRZZUtvMg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L6pobpMYhcMY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}